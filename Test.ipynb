{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Problem Definition\n",
    "\n",
    "In our case, the problem we will be exploring is _binary classification_ (a sample can only be one of two things).\n",
    "\n",
    "This is because we're going to be using a number of different _features_ (pieces of information) about a person to predict whether they have heart disease or not.\n",
    "\n",
    "In a statement,\n",
    "\n",
    "> Given clinical parameters about a patient, can we predict whether they have heart disease?\n",
    "\n",
    "# 2. Data\n",
    "\n",
    "What you'll want to do here is dive into the data your problem definition is based on. This may involve, sourcing, defining different parameters, talking to experts about it and finding out what you should expect.\n",
    "\n",
    "The original data came from the <a src=\"https://archive.ics.uci.edu/ml/datasets/heart+Disease\"> Cleveland database </a> from UCI Machine Learning Repository.\n",
    "\n",
    "However, we've downloaded it in a formatted way from Kaggle.\n",
    "\n",
    "The original database contains 76 attributes, but here only 14 attributes will be used. _Attributes_ (also called _features_) are the variables what we'll use to predict our _target variable_.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "# Regular EDA and plotting libraries\n",
    "import numpy as np  # np is short for numpy\n",
    "import pandas as pd  # pandas is so commonly used, it's shortened to pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # seaborn gets shortened to sns\n",
    "\n",
    "# We want our plots to appear in the notebook\n",
    "% matplotlib inline\n",
    "\n",
    "## Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Model evaluators\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart-disease.csv\")  # 'DataFrame' shortened to 'df'\n",
    "df.shape  # (rows, columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's check the top 5 rows of our dataframe\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# And the top 10\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's see how many positive (1) and negative (0) samples we have in our dataframe\n",
    "df.target.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Normalized value counts\n",
    "df.target.value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the value counts with a bar graph\n",
    "df.target.value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"]);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare target column with sex column\n",
    "pd.crosstab(df.target, df.sex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "pd.crosstab(df.target, df.sex).plot(kind=\"bar\",\n",
    "                                    figsize=(10, 6),\n",
    "                                    color=[\"salmon\", \"lightblue\"]);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "pd.crosstab(df.target, df.sex).plot(kind=\"bar\", figsize=(10, 6), color=[\"salmon\", \"lightblue\"])\n",
    "\n",
    "# Add some attributes to it\n",
    "plt.title(\"Heart Disease Frequency for Sex\")\n",
    "plt.xlabel(\"0 = No Disease, 1 = Disease\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.legend([\"Female\", \"Male\"])\n",
    "plt.xticks(rotation=0);  # keep the labels on the x-axis vertical"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create another figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Start with positve examples\n",
    "plt.scatter(df.age[df.target == 1],\n",
    "            df.thalach[df.target == 1],\n",
    "            c=\"salmon\")  # define it as a scatter figure\n",
    "\n",
    "# Now for negative examples, we want them on the same plot, so we call plt again\n",
    "plt.scatter(df.age[df.target == 0],\n",
    "            df.thalach[df.target == 0],\n",
    "            c=\"lightblue\")  # axis always come as (x, y)\n",
    "\n",
    "# Add some helpful info\n",
    "plt.title(\"Heart Disease in function of Age and Max Heart Rate\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.legend([\"Disease\", \"No Disease\"])\n",
    "plt.ylabel(\"Max Heart Rate\");"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Histograms are a great way to check the distribution of a variable\n",
    "df.age.plot.hist();"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.crosstab(df.cp, df.target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a new crosstab and base plot\n",
    "pd.crosstab(df.cp, df.target).plot(kind=\"bar\",\n",
    "                                   figsize=(10, 6),\n",
    "                                   color=[\"lightblue\", \"salmon\"])\n",
    "\n",
    "# Add attributes to the plot to make it more readable\n",
    "plt.title(\"Heart Disease Frequency Per Chest Pain Type\")\n",
    "plt.xlabel(\"Chest Pain Type\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend([\"No Disease\", \"Disease\"])\n",
    "plt.xticks(rotation=0);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find the correlation between our independent variables\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Let's make it look a little prettier\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix,\n",
    "            annot=True,\n",
    "            linewidths=0.5,\n",
    "            fmt=\".2f\",\n",
    "            cmap=\"YlGnBu\");"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Everything except target variable\n",
    "X = df.drop(\"target\", axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = df.target.values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Independent variables (no target column)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Targets\n",
    "y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into train & test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,  # independent variables\n",
    "                                                    y,  # dependent variable\n",
    "                                                    test_size=0.2)  # percentage of data to use for test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train, len(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test, len(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Put models in a dictionary\n",
    "models = {\"KNN\": KNeighborsClassifier(),\n",
    "          \"Logistic Regression\": LogisticRegression(),\n",
    "          \"Random Forest\": RandomForestClassifier()}\n",
    "\n",
    "\n",
    "# Create function to fit and score models\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluates given machine learning models.\n",
    "    models : a dict of different Scikit-Learn machine learning models\n",
    "    X_train : training data\n",
    "    X_test : testing data\n",
    "    y_train : labels assosciated with training data\n",
    "    y_test : labels assosciated with test data\n",
    "    \"\"\"\n",
    "    # Random seed for reproducible results\n",
    "    np.random.seed(42)\n",
    "    # Make a list to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        # Fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # Evaluate the model and append its score to model_scores\n",
    "        model_scores[name] = model.score(X_test, y_test)\n",
    "    return model_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_scores = fit_and_score(models=models,\n",
    "                             X_train=X_train,\n",
    "                             X_test=X_test,\n",
    "                             y_train=y_train,\n",
    "                             y_test=y_test)\n",
    "model_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_compare = pd.DataFrame(model_scores, index=['accuracy'])\n",
    "model_compare.T.plot.bar();"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a list of train scores\n",
    "train_scores = []\n",
    "\n",
    "# Create a list of test scores\n",
    "test_scores = []\n",
    "\n",
    "# Create a list of different values for n_neighbors\n",
    "neighbors = range(1, 21)  # 1 to 20\n",
    "\n",
    "# Setup algorithm\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Loop through different neighbors values\n",
    "for i in neighbors:\n",
    "    knn.set_params(n_neighbors=i)  # set neighbors value\n",
    "\n",
    "    # Fit the algorithm\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Update the training scores\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "\n",
    "    # Update the test scores\n",
    "    test_scores.append(knn.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(neighbors, train_scores, label=\"Train score\")\n",
    "plt.plot(neighbors, test_scores, label=\"Test score\")\n",
    "plt.xticks(np.arange(1, 21, 1))\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Model score\")\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Maximum KNN score on the test data: {max(test_scores) * 100:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Different LogisticRegression hyperparameters\n",
    "log_reg_grid = {\"C\": np.logspace(-4, 4, 20),\n",
    "                \"solver\": [\"liblinear\"]}\n",
    "\n",
    "# Different RandomForestClassifier hyperparameters\n",
    "rf_grid = {\"n_estimators\": np.arange(10, 1000, 50),\n",
    "           \"max_depth\": [None, 3, 5, 10],\n",
    "           \"min_samples_split\": np.arange(2, 20, 2),\n",
    "           \"min_samples_leaf\": np.arange(1, 20, 2)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup random hyperparameter search for LogisticRegression\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
    "                                param_distributions=log_reg_grid,\n",
    "                                cv=5,\n",
    "                                n_iter=20,\n",
    "                                verbose=True)\n",
    "\n",
    "# Fit random hyperparameter search model\n",
    "rs_log_reg.fit(X_train, y_train);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rs_log_reg.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rs_log_reg.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup random hyperparameter search for RandomForestClassifier\n",
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                           param_distributions=rf_grid,\n",
    "                           cv=5,\n",
    "                           n_iter=20,\n",
    "                           verbose=True)\n",
    "\n",
    "# Fit random hyperparameter search model\n",
    "rs_rf.fit(X_train, y_train);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find the best parameters\n",
    "rs_rf.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the randomized search random forest model\n",
    "rs_rf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Different LogisticRegression hyperparameters\n",
    "log_reg_grid = {\"C\": np.logspace(-4, 4, 20),\n",
    "                \"solver\": [\"liblinear\"]}\n",
    "\n",
    "# Setup grid hyperparameter search for LogisticRegression\n",
    "gs_log_reg = GridSearchCV(LogisticRegression(),\n",
    "                          param_grid=log_reg_grid,\n",
    "                          cv=5,\n",
    "                          verbose=True)\n",
    "\n",
    "# Fit grid hyperparameter search model\n",
    "gs_log_reg.fit(X_train, y_train);\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check the best parameters\n",
    "gs_log_reg.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "gs_log_reg.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make preidctions on test data\n",
    "y_preds = gs_log_reg.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import ROC curve function from metrics module\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# Plot ROC curve and calculate AUC metric\n",
    "plot_roc_curve(gs_log_reg, X_test, y_test);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "print(confusion_matrix(y_test, y_preds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5)  # Increase font size\n",
    "\n",
    "\n",
    "def plot_conf_mat(y_test, y_preds):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap().\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax = sns.heatmap(confusion_matrix(y_test, y_preds),\n",
    "                     annot=True,  # Annotate the boxes\n",
    "                     cbar=False)\n",
    "    plt.xlabel(\"true label\")\n",
    "    plt.ylabel(\"predicted label\")\n",
    "\n",
    "\n",
    "plot_conf_mat(y_test, y_preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show classification report\n",
    "print(classification_report(y_test, y_preds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check best hyperparameters\n",
    "gs_log_reg.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Instantiate best model with best hyperparameters (found with GridSearchCV)\n",
    "clf = LogisticRegression(C=0.23357214690901212,\n",
    "                         solver=\"liblinear\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cross-validated accuracy score\n",
    "cv_acc = cross_val_score(clf,\n",
    "                         X,\n",
    "                         y,\n",
    "                         cv=5,  # 5-fold cross-validation\n",
    "                         scoring=\"accuracy\")  # accuracy as scoring\n",
    "cv_acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cross-validated precision score\n",
    "cv_precision = np.mean(cross_val_score(clf,\n",
    "                                       X,\n",
    "                                       y,\n",
    "                                       cv=5,  # 5-fold cross-validation\n",
    "                                       scoring=\"precision\"))  # precision as scoring\n",
    "cv_precision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cross-validated recall score\n",
    "cv_recall = np.mean(cross_val_score(clf,\n",
    "                                    X,\n",
    "                                    y,\n",
    "                                    cv=5,  # 5-fold cross-validation\n",
    "                                    scoring=\"recall\"))  # recall as scoring\n",
    "cv_recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cross-validated F1 score\n",
    "cv_f1 = np.mean(cross_val_score(clf,\n",
    "                                X,\n",
    "                                y,\n",
    "                                cv=5,  # 5-fold cross-validation\n",
    "                                scoring=\"f1\"))  # f1 as scoring\n",
    "cv_f1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualizing cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({\"Accuracy\": cv_acc,\n",
    "                           \"Precision\": cv_precision,\n",
    "                           \"Recall\": cv_recall,\n",
    "                           \"F1\": cv_f1},\n",
    "                          index=[0])\n",
    "cv_metrics.T.plot.bar(title=\"Cross-Validated Metrics\", legend=False);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit an instance of LogisticRegression (taken from above)\n",
    "clf.fit(X_train, y_train);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check coef_\n",
    "clf.coef_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Match features to columns\n",
    "features_dict = dict(zip(df.columns, list(clf.coef_[0])))\n",
    "features_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "features_df = pd.DataFrame(features_dict, index=[0])\n",
    "features_df.T.plot.bar(title=\"Feature Importance\", legend=False);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.crosstab(df[\"sex\"], df[\"target\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Contrast slope (positive coefficient) with target\n",
    "pd.crosstab(df[\"slope\"], df[\"target\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
